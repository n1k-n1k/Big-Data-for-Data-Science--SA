## Проект часть II

### Data Engineering

Мы с вами уже исследовали данные, которые у нас есть.

Теперь нам необходимо будет обработать наши данные и подготовить их к обучению моделей.

Для этого выделим ключевые параметры и определим целевую фичу (`CTR`).

При этом наши данные могут впоследствии изменяться, накапливаться и достигать больших объемов, 
поэтому нам необходимо реализовать задачу обработки данных, которую мы при необходимости сможем многократно 
выполнять для получения результата над любым объемом данных.

Структура данных:

- `date` - день, в который происходят события
- `time` - точное время события
- `event` - тип события, может быть или показ или клик по рекламе
- `platform` - платформа, на которой произошло рекламное событие
- `ad_id` - id рекламного объявления
- `client_union_id` - id рекламного клиента
- `campaign_union_id` - id рекламной кампании
- `ad_cost_type` - тип объявления с оплатой за клики (CPC) или за показы (CPM)
- `ad_cost` - стоимость объявления в рублях, для CPC объявлений - это цена за клик, для CPM - цена за 1000 показов
- `has_video` - есть ли у рекламного объявления видео
- `target_audience_count` - размер аудитории, на которую таргетируется объявление

Представьте, что все ваши инженеры по данным заболели, но и один в поле воин! 

У вас есть отличный шанс удивить их! Вам необходимо реализовать на `PySpark` задачу обработки данных для их подготовки к обучению моделей.

В результате выполнения вашей задачи, например, выполнив команду:

`spark-submit PySparkJob.py clickstream.parquet result`

или 

`python PySparkJob.py clickstream.parquet result`

Вы должны прочитать указанный в параметрах файл, обработать его и получить структуру папок вида:

```
- /result/train
- /result/test
- /result/validate
```

С наборами данных в следующем соотношении `train/test/validate = 0.5/0.25/0.25 (randomSplit)`.

В каждой папке должен находиться `parquet`-файл (число партиций не принципиально) со следующей структурой данных:

- `ad_id` [integer] - id рекламного объявления
- `target_audience_count` [decimal] -	размер аудитории, на которую таргетируется объявление
- `has_video` [integer] - 1 если есть видео, иначе 0
- `is_cpm` [integer] - 1 если тип объявления CPM, иначе 0
- `is_cpc` [integer] - 1 если тип объявления CPC, иначе 0
- `ad_cost` [double] - стоимость объявления в рублях
- `day_count` [integer] - Число дней, которое показывалась реклама
- `CTR`	[double] - Отношение числа кликов к числу просмотров

Пожалуйста, используйте шаблон [PySparkJob.py](https://raw.githubusercontent.com/AlexKbit/stepik-ds-course/master/Week3/Project/PySparkJob.py)
- [Документация](https://spark.apache.org/docs/latest/api/python/index.html)
- [Файл с данными](https://github.com/AlexKbit/stepik-ds-course/raw/master/Week3/Project/clickstream.parquet)

**Формат решения**: `PySparkJob.py` файл с реализованным кодом.

##### Рецензия преподавателя:
```
Все отлично, очень хорошая работа и без усложнений. Вам удалось полностью избежать тяжелых join операций. 
```
