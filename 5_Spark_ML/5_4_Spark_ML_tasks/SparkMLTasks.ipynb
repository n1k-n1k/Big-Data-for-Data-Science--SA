{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>Курс: </b>Big Data for Data Science</p>\n",
    "    <p><b>Раздел: </b>5. Spark ML - задачи</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "#set seed\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Tech:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x289bd633fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №1 Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные для применения линейной регрессии <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/linear_regression.parquet\">linear_regression.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = spark.read.parquet('_data\\linear_regression.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте учителя линейной регресии со следующими параметрами:\n",
    "maxIter=20\n",
    "regParam=0.5\n",
    "elasticNetParam=0.75<br>\n",
    "<a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-regression\">LinearRegression</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(maxIter=20, regParam=0.5, elasticNetParam=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните обучения на загруженных данных и сохраните результат в переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(lr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите следующие параметры полученной модели rootMeanSquaredError (RMSE), r2 и округлити их до 3его знака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 10.217, r2 = 0.017\n"
     ]
    }
   ],
   "source": [
    "lr_prediction = lrModel.transform(lr_df)\n",
    "evaluator_RMSE = RegressionEvaluator(metricName='rmse')\n",
    "evaluator_r2 = RegressionEvaluator(metricName='r2')\n",
    "\n",
    "print(f'RMSE = {round(evaluator_RMSE.evaluate(lr_prediction), 3)}, r2 = {round(evaluator_r2.evaluate(lr_prediction), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №2 Кластеризация (K-Means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные для применения из <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/wine.parquet\">wine.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = spark.read.parquet('_data\\wine.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+\n",
      "|Alcohol|Malic_Acid| Ash|Ash_Alcanity|Magnesium|Total_Phenols|Flavanoids|Nonflavanoid_Phenols|Proanthocyanins|Color_Intensity| Hue|OD280|Proline|Customer_Segment|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+\n",
      "|  14.23|      1.71|2.43|        15.6|      127|          2.8|      3.06|                0.28|           2.29|           5.64|1.04| 3.92|   1065|               1|\n",
      "|   13.2|      1.78|2.14|        11.2|      100|         2.65|      2.76|                0.26|           1.28|           4.38|1.05|  3.4|   1050|               1|\n",
      "|  13.16|      2.36|2.67|        18.6|      101|          2.8|      3.24|                 0.3|           2.81|           5.68|1.03| 3.17|   1185|               1|\n",
      "|  14.37|      1.95| 2.5|        16.8|      113|         3.85|      3.49|                0.24|           2.18|            7.8|0.86| 3.45|   1480|               1|\n",
      "|  13.24|      2.59|2.87|        21.0|      118|          2.8|      2.69|                0.39|           1.82|           4.32|1.04| 2.93|    735|               1|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wine_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> для создания вектора фич (задействуйте все свойства, кроме Customer_Segment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=wine_df.columns[0:-1], outputCol='features').transform(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+--------------------+\n",
      "|Alcohol|Malic_Acid| Ash|Ash_Alcanity|Magnesium|Total_Phenols|Flavanoids|Nonflavanoid_Phenols|Proanthocyanins|Color_Intensity| Hue|OD280|Proline|Customer_Segment|            features|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+--------------------+\n",
      "|  14.23|      1.71|2.43|        15.6|      127|          2.8|      3.06|                0.28|           2.29|           5.64|1.04| 3.92|   1065|               1|[14.23,1.71,2.43,...|\n",
      "|   13.2|      1.78|2.14|        11.2|      100|         2.65|      2.76|                0.26|           1.28|           4.38|1.05|  3.4|   1050|               1|[13.2,1.78,2.14,1...|\n",
      "|  13.16|      2.36|2.67|        18.6|      101|          2.8|      3.24|                 0.3|           2.81|           5.68|1.03| 3.17|   1185|               1|[13.16,2.36,2.67,...|\n",
      "|  14.37|      1.95| 2.5|        16.8|      113|         3.85|      3.49|                0.24|           2.18|            7.8|0.86| 3.45|   1480|               1|[14.37,1.95,2.5,1...|\n",
      "|  13.24|      2.59|2.87|        21.0|      118|          2.8|      2.69|                0.39|           1.82|           4.32|1.04| 2.93|    735|               1|[13.24,2.59,2.87,...|\n",
      "+-------+----------+----+------------+---------+-------------+----------+--------------------+---------------+---------------+----+-----+-------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cоздайте учителя KMeans со следующими параметрами K=3 Seed=1<br>\n",
    "Обучите модель и примените ее к тому же вектору.\n",
    "Документация по <a href=\"https://spark.apache.org/docs/latest/ml-clustering.html#k-means\">KMeans</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans().setK(3).setSeed(1)\n",
    "model = kmeans.fit(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите силуэт с евклидовым расстоянием в квадрате для данных по вину(округлите до четвертого знака).\n",
    "<br><a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.ClusteringEvaluator\">ClusteringEvaluator</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_prediction = model.transform(feature)\n",
    "evaluator = ClusteringEvaluator()\n",
    "round(evaluator.evaluate(wine_prediction), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №3 DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузити датасет из файла <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/iris.parquet\">iris.parquet</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = #Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте из наших признаков вектор применив <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\">VectorAssembler</a> как колонку features.\n",
    "<br> Задействуйте все признаки, кроме species, так как он является целевым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/ml-features.html#stringindexer\">StringIndexer</a> и сделайте новый признак с именем type из целевого признака species который является категориальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем выборки на обучение и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = iris_df.randomSplit([0.8, 0.2],seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте и обучите <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier\">DecisionTreeClassifier</a> на датасете для обучения.\n",
    "Полученную модель используйте над тестовым датасетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a> (помните что целевая фича это - type) для оценки качества модели по метрике accuracy.<br>Какая точность полученной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №4 Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте и обучите <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\">RandomForestClassifier</a> из 10 деревьев на датасете для обучения.\n",
    "Полученную модель примените к тестовому датасету.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a> (помните что целевая фича это - type) для оценки качества модели по метрике accuracy.<br>Какая точность полученной модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## №5 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Займемся оптимизацией гиперпараметров для модели.\n",
    "Примените <a href='https://spark.apache.org/docs/latest/ml-tuning.html#train-validation-split'>TrainValidationSplit</a> для оптимизации гиперпараметров используя подготовленный вами выше датасет <a href=\"https://github.com/AlexKbit/stepik-ds-course/raw/master/Week5/SparkML/spark-tasks/iris.parquet\">iris.parquet</a> на модели <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\">RandomForestClassifier</a> совместно с <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">MulticlassClassificationEvaluator</a>.\n",
    "<br>Ваша цель определить оптимальные значения параметров из следующих диапазонов:\n",
    "<br>impurity = [\"entropy\", \"gini\"]\n",
    "<br>maxDepth = [2, 3, 4, 5]\n",
    "<br>numTrees = [3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = #Ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Num Trees: {}'.format(model.bestModel._java_obj.getNumTrees()))\n",
    "print('Max Depth: {}'.format(model.bestModel._java_obj.getMaxDepth()))\n",
    "print('Impurity: {}'.format(model.bestModel._java_obj.getImpurity()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
